{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596146365379",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "# For data manipulation\n",
    "import pandas as pd\n",
    "# For matrix operations\n",
    "import numpy as np\n",
    "# For numerical division\n",
    "from __future__ import division\n",
    "# For regular expression (text cleaning)\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                             content  label\n0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n1  martin a posted tassos papadopoulos the greek ...      0\n2  man threatens explosion in moscow thursday aug...      0\n3  klez the virus that won t die already the most...      0\n4   in adding cream to spaghetti carbonara which ...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>martin a posted tassos papadopoulos the greek ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man threatens explosion in moscow thursday aug...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>klez the virus that won t die already the most...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in adding cream to spaghetti carbonara which ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "# Load data set and display a few observations\n",
    "data = pd.read_csv('C:\\\\code\\\\ML-practicE\\\\shit-easy projects for practice smth\\\\algorithms without libs\\\\datasets\\\\data_spam.csv')\n",
    "# Create column labels\n",
    "data.columns = [\"content\",\"label\"]\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             label        length\ncount  3000.000000   3000.000000\nmean      0.166667    235.882667\nstd       0.372740    562.174964\nmin       0.000000      0.000000\n25%       0.000000     67.000000\n50%       0.000000    134.000000\n75%       0.000000    235.000000\nmax       1.000000  13303.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3000.000000</td>\n      <td>3000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.166667</td>\n      <td>235.882667</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.372740</td>\n      <td>562.174964</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>67.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>134.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>235.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>13303.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "# Add another column with corresponding comment length\n",
    "data['length'] = data['content'].map(lambda text: len(str(text).split()))\n",
    "\n",
    "# Summary statistics (mean, stdev, min, max)\n",
    "data[[\"label\",\"length\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "count    2254.000000\nmean        0.161491\nstd         0.368065\nmin         0.000000\n25%         0.000000\n50%         0.000000\n75%         0.000000\nmax         1.000000\nName: label, dtype: float64"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "# Set seed so we get same random allocation on each run of code\n",
    "np.random.seed(2017)\n",
    "\n",
    "# Add column vector of randomly generated numbers form U[0,1]\n",
    "data[\"uniform\"] = np.random.uniform(0,1,len(data.index)) \n",
    "\n",
    "# About 75% of these numbers should be less than 0.75\n",
    "data_train = data[data[\"uniform\"] < 0.75]\n",
    "\n",
    "# About 25% of these numbers should be more than 0.75\n",
    "data_test = data[data[\"uniform\"] > 0.75]\n",
    "\n",
    "# Check that both training and test data have both spam and ham comments\n",
    "data_train[\"label\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "count    746.000000\nmean       0.182306\nstd        0.386355\nmin        0.000000\n25%        0.000000\n50%        0.000000\n75%        0.000000\nmax        1.000000\nName: label, dtype: float64"
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "# Test data summary statistics\n",
    "data_test[\"label\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unique words in training data: 26393\nFirst 5 words in our unique set of words: \n ['sachs', 'personnal', 'being', 'plug', 'coords']\n"
    }
   ],
   "source": [
    "# Join all the comments into a big list\n",
    "training_list_words = \"\".join(data_train.iloc[:,0].values)\n",
    "\n",
    "# Split the list of comments into a list of unique words\n",
    "train_unique_words = set(training_list_words.split(' '))\n",
    "\n",
    "# Number of unique words in training \n",
    "vocab_size_train = len(train_unique_words)\n",
    "\n",
    "# Description of summarized comments in training data\n",
    "print('Unique words in training data: %s' % vocab_size_train)\n",
    "print('First 5 words in our unique set of words: \\n % s' % list(train_unique_words)[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unique words in processed training data: 25678\nFirst 5 words in our processed unique set of words: \n ['sachs', 'personnal', 'being', 'plug', 'coords']\n"
    }
   ],
   "source": [
    "# Only keep letters and numbers\n",
    "train_unique_words = [re.sub(r'[^a-zA-Z0-9]','', words) for words in train_unique_words]\n",
    "\n",
    "# Convert to lower case and get unique set of words\n",
    "train_unique_words = set([words.lower() for words in train_unique_words])\n",
    "\n",
    "# Number of unique words in training \n",
    "vocab_size_train = len(train_unique_words)\n",
    "\n",
    "# Description of summarized comments in training data\n",
    "print('Unique words in processed training data: %s' % vocab_size_train)\n",
    "print('First 5 words in our processed unique set of words: \\n % s' % list(train_unique_words)[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with comment words as \"keys\", and their label as \"value\"\n",
    "trainPositive = dict()\n",
    "trainNegative = dict()\n",
    "\n",
    "# Intiailize classes\n",
    "positiveTotal = 0\n",
    "negativeTotal = 0\n",
    "\n",
    "# Initialize Prob. of\n",
    "pSpam = 0.0\n",
    "pNotSpam = 0.0\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def initialize_dicts():\n",
    "\n",
    "# Initialize dictionary of words and their labels   \n",
    "for word in train_unique_words:\n",
    "    \n",
    "    # Classify all words for now as ham (legitimate)\n",
    "    trainPositive[word] = 0\n",
    "    trainNegative[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\n"
    }
   ],
   "source": [
    "# Count number of times word in comment appear in spam and ham comments\n",
    "def processEmail(email,label):\n",
    "    global positiveTotal\n",
    "    global negativeTotal\n",
    "    \n",
    "    # Split comments into words\n",
    "    email = email.split(' ')\n",
    "    \n",
    "    # Go over each word in email\n",
    "    for word in email:\n",
    "        \n",
    "        # ham commments\n",
    "        if(label == 0 and word != ' '):\n",
    "            \n",
    "            # Increment number of times word appears in ham emails\n",
    "            trainNegative[word] = trainNegative.get(word,0)+1\n",
    "            negativeTotal += 1\n",
    "            \n",
    "        # spam comments\n",
    "        elif(label == 1 and word != ' '):\n",
    "            \n",
    "            # Increment number of times word appears in spam comments\n",
    "            trainPositive[word] = trainPositive.get(word,0)+1\n",
    "            positiveTotal += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Prob(word|spam) and Prob(word|ham)\n",
    "def conditionalWord(word,label):\n",
    "    \n",
    "    # Laplace smoothing parameter\n",
    "    global alpha\n",
    "    \n",
    "    # word in ham email\n",
    "    if(label == 0):\n",
    "        # Compute Prob(word|ham)\n",
    "        return (trainNegative.get(word,0)+alpha)/(float)(negativeTotal+alpha*vocab_size_train)\n",
    "    \n",
    "    # word in spam email\n",
    "    else:\n",
    "        \n",
    "        # Compute Prob(word|ham)\n",
    "        return (trainPositive.get(word,0)+alpha)/(float)(positiveTotal+alpha*vocab_size_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Prob(spam|comment) or Prob(ham|comment)\n",
    "def conditionalEmail(email,label):\n",
    "    \n",
    "    # Initialize conditional probability\n",
    "    prob_label_email = 1.0\n",
    "    \n",
    "    # Split comments into list of words\n",
    "    email = str(email).split(' ')\n",
    "    \n",
    "    # Go through all words in emails\n",
    "    for word in email:\n",
    "        \n",
    "        # Compute value proportional to Prob(label|email)\n",
    "        # Conditional indepdence is assumed here\n",
    "        prob_label_email *= conditionalWord(word,label)\n",
    "    \n",
    "    return prob_label_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train naive bayes by computing several conditional probabilities in training data\n",
    "def train():\n",
    "    \n",
    "    print('Starting training')\n",
    "    global pSpam\n",
    "    global pNotSpam\n",
    "\n",
    "    # Initiailize \n",
    "    total = 0\n",
    "    numNegative = 0\n",
    "    \n",
    "    # Go over each email in training data\n",
    "    for idx, email in data_train.iterrows():\n",
    "        \n",
    "        # Comment is ham \n",
    "        if email.label == 0:\n",
    "            \n",
    "            # Increment ham email counter\n",
    "            numNegative += 1\n",
    "        \n",
    "        # Increment comment number\n",
    "        total += 1\n",
    "        \n",
    "        # Update dictionary of ham and spam comments\n",
    "        processEmail(email.content,email.label)\n",
    "    \n",
    "    # Compute prior probabilities, P(spam), P(ham)\n",
    "    pSpam = numNegative/float(total)\n",
    "    pNotSpam = (total - numNegative)/float(total)\n",
    "    \n",
    "    print('Training is now finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting training\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'ttrainNegative' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-129-3d1bcf8abcf4>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Update dictionary of ham and spam comments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mprocessEmail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0memail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# Compute prior probabilities, P(spam), P(ham)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-126-04a84b525c8b>\u001b[0m in \u001b[0;36mprocessEmail\u001b[1;34m(email, label)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m# Increment number of times word appears in ham emails\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mtrainNegative\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainNegative\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0maa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mttrainNegative\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hello'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mnegativeTotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ttrainNegative' is not defined"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify comment are spam or ham\n",
    "def classify(email):\n",
    "    \n",
    "    global pSpam\n",
    "    global pNotSpam\n",
    "    \n",
    "    # Compute value proportional to Pr(comment|ham)\n",
    "    isNegative = pSpam * conditionalEmail(email,0)\n",
    "    \n",
    "    # Compute value proportional to Pr(comment|spam)\n",
    "    isPositive = pNotSpam * conditionalEmail(email,1)\n",
    "    \n",
    "    # Output True = spam, False = ham\n",
    "    return (isNegative < isPositive)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Proportion of comments classified correctly on test set: 0.8176943699731903\n"
    }
   ],
   "source": [
    "# Initialize spam prediction in test data\n",
    "prediction_test = []\n",
    "\n",
    "# Get prediction accuracy on test data\n",
    "for email in data_test[\"content\"]:\n",
    "\n",
    "    # Classify comment \n",
    "    prediction_test.append(classify(email))\n",
    "\n",
    "# Check accuracy\n",
    "test_accuracy = np.mean(np.equal(prediction_test, data_test[\"label\"]))\n",
    "\n",
    "#print prediction_test\n",
    "print(\"Proportion of comments classified correctly on test set: %s\" % test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "classify('FREE gift special for you right now!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute tfidf(word, comment, data)\n",
    "def TFIDF(email, train):\n",
    "    \n",
    "    # Split comment into list of words\n",
    "    email = email.split(' ')\n",
    "    \n",
    "    # Initiailize tfidf for given comment\n",
    "    tfidf_email = np.zeros(len(email))\n",
    "    \n",
    "    # Initiailize number of comments containing a word\n",
    "    num_email_word = 0\n",
    "    \n",
    "    # Intialize index for words in email\n",
    "    word_index = 0\n",
    "    \n",
    "    # Go over all words in comment\n",
    "    for word in email:\n",
    "        \n",
    "        # Compute term frequence (tf)\n",
    "        # Count frequency of word in email\n",
    "        tf = email.count(word)\n",
    "        \n",
    "        # Find number of emails containing word\n",
    "        for text in train[\"content\"]:\n",
    "            \n",
    "            # Increment word counter if word found in comment\n",
    "            if text.split(' ').count(word) > 0:\n",
    "                num_email_word += 1\n",
    "        \n",
    "        # Compute inverse document frequency (idf)\n",
    "        # log(Total number of emails/number of comments with word)\n",
    "        if num_email_word == 0:\n",
    "            idf = np.log(len(train.index)/(num_email_word+1))\n",
    "        else:\n",
    "            idf = np.log(len(train.index)/num_email_word)\n",
    "        \n",
    "        # Update tf-idf weight for word\n",
    "        tfidf_email[word_index] = tf*idf\n",
    "        \n",
    "        # Reset comment containing word counter\n",
    "        num_email_word = 0\n",
    "        \n",
    "        # Move onto next word in email\n",
    "        word_index += 1\n",
    "        \n",
    "    return tfidf_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([7.72046169, 1.27792153, 1.21020335, 1.49195069, 3.98279208,\n       4.35316586, 7.72046169])"
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "TFIDF(\"Check out my new music video plz\",data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "source": [
    "classify(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}