{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595113219344",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   g1freelunch  g1absent  g1readscore  g1mathscore  g1listeningscore  \\\n0            1         9          516          578               601   \n1            0        12          451          507               584   \n2            1         4          483          526               529   \n3            1        15          516          505               556   \n4            1         2          433          463               504   \n\n   g1wordscore  \n0          493  \n1          436  \n2          486  \n3          536  \n4          426  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>g1freelunch</th>\n      <th>g1absent</th>\n      <th>g1readscore</th>\n      <th>g1mathscore</th>\n      <th>g1listeningscore</th>\n      <th>g1wordscore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>9</td>\n      <td>516</td>\n      <td>578</td>\n      <td>601</td>\n      <td>493</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>12</td>\n      <td>451</td>\n      <td>507</td>\n      <td>584</td>\n      <td>436</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>4</td>\n      <td>483</td>\n      <td>526</td>\n      <td>529</td>\n      <td>486</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>15</td>\n      <td>516</td>\n      <td>505</td>\n      <td>556</td>\n      <td>536</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2</td>\n      <td>433</td>\n      <td>463</td>\n      <td>504</td>\n      <td>426</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#numpy for matrix \n",
    "import numpy as np\n",
    "#pandas for data manipulation \n",
    "import pandas as pd \n",
    "#data visualization\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#seed\n",
    "np.random.seed(2017)\n",
    "\n",
    "#loading the data\n",
    "educ_data = pd.read_csv('C:\\\\code\\\\ML-practicE\\\\shit-easy projects for practice smth\\\\algorithms without libs\\\\datasets\\\\Grade1Students.csv')\n",
    "\n",
    "#Show stuctures\n",
    "educ_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       g1freelunch     g1absent  g1readscore  g1mathscore  g1listeningscore  \\\ncount  5550.000000  5550.000000  5550.000000  5550.000000       5550.000000   \nmean      0.500901     7.421261   521.307207   531.456216        567.824324   \nstd       0.500044     7.004582    55.278448    43.151113         33.562973   \nmin       0.000000     0.000000   404.000000   404.000000        477.000000   \n25%       0.000000     2.000000   478.000000   502.000000        543.000000   \n50%       1.000000     6.000000   516.000000   529.000000        565.000000   \n75%       1.000000    10.000000   558.000000   562.000000        588.000000   \nmax       1.000000    84.000000   651.000000   676.000000        708.000000   \n\n       g1wordscore  \ncount  5550.000000  \nmean    514.643063  \nstd      52.858396  \nmin     317.000000  \n25%     475.000000  \n50%     514.000000  \n75%     551.000000  \nmax     601.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>g1freelunch</th>\n      <th>g1absent</th>\n      <th>g1readscore</th>\n      <th>g1mathscore</th>\n      <th>g1listeningscore</th>\n      <th>g1wordscore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5550.000000</td>\n      <td>5550.000000</td>\n      <td>5550.000000</td>\n      <td>5550.000000</td>\n      <td>5550.000000</td>\n      <td>5550.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.500901</td>\n      <td>7.421261</td>\n      <td>521.307207</td>\n      <td>531.456216</td>\n      <td>567.824324</td>\n      <td>514.643063</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.500044</td>\n      <td>7.004582</td>\n      <td>55.278448</td>\n      <td>43.151113</td>\n      <td>33.562973</td>\n      <td>52.858396</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>404.000000</td>\n      <td>404.000000</td>\n      <td>477.000000</td>\n      <td>317.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>478.000000</td>\n      <td>502.000000</td>\n      <td>543.000000</td>\n      <td>475.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>6.000000</td>\n      <td>516.000000</td>\n      <td>529.000000</td>\n      <td>565.000000</td>\n      <td>514.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>10.000000</td>\n      <td>558.000000</td>\n      <td>562.000000</td>\n      <td>588.000000</td>\n      <td>551.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>84.000000</td>\n      <td>651.000000</td>\n      <td>676.000000</td>\n      <td>708.000000</td>\n      <td>601.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#Summary statistics for the data set\n",
    "educ_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will normalize each feature to have mean 0 and standard deviation 1\n",
    "# This standardization is done to represent input data on the same scale\n",
    "\n",
    "# Standardize free lunch status\n",
    "educ_data[\"g1freelunch\"] = (educ_data[\"g1freelunch\"]-np.mean(educ_data[\"g1freelunch\"]))/np.std(educ_data[\"g1freelunch\"])\n",
    "\n",
    "# Standardize absences \n",
    "educ_data[\"g1absent\"] = (educ_data[\"g1absent\"]-np.mean(educ_data[\"g1absent\"]))/np.std(educ_data[\"g1absent\"])\n",
    "\n",
    "# Standardize reading score\n",
    "educ_data[\"g1readscore\"] = (educ_data[\"g1readscore\"]-np.mean(educ_data[\"g1readscore\"]))/np.std(educ_data[\"g1readscore\"])\n",
    "\n",
    "# Standardize math score\n",
    "educ_data[\"g1mathscore\"] = (educ_data[\"g1mathscore\"]-np.mean(educ_data[\"g1mathscore\"]))/np.std(educ_data[\"g1mathscore\"])\n",
    "\n",
    "# Standardize listening score\n",
    "educ_data[\"g1listeningscore\"] = (educ_data[\"g1listeningscore\"]-np.mean(educ_data[\"g1listeningscore\"]))/np.std(educ_data[\"g1listeningscore\"])\n",
    "\n",
    "# Standardized word study score\n",
    "educ_data[\"g1wordscore\"] = (educ_data[\"g1wordscore\"]-np.mean(educ_data[\"g1wordscore\"]))/np.std(educ_data[\"g1wordscore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Initialized weight matrix, [[ 0.29258533 -1.68141927  0.4667529 ]\n [-1.71926387 -0.18965199 -0.15046866]\n [-0.63240642 -0.7812671  -0.67740072]\n [-0.19819022 -0.29255102 -0.25761752]\n [-0.23453879 -1.1255962   1.59932537]\n [-1.23392882 -0.92271883  0.35753994]]\nTrained weights from SOM, [[ 0.90212207 -0.19966709 -0.56332296]\n [ 0.09685719 -0.1126318  -0.1866428 ]\n [-1.08109289 -0.10474967  1.29763563]\n [-0.90824374  0.00563766  1.26342202]\n [-0.83703618  0.07549108  1.05139537]\n [-1.10931415  0.02766761  1.09598478]]\n"
    }
   ],
   "source": [
    "# Initialize total number of itterations (remember n = 5550)\n",
    "total_itter = 3*len(educ_data.index)\n",
    "\n",
    "# Initialize number of output nodes\n",
    "nodes_num = 3\n",
    "\n",
    "# Dimension of input data\n",
    "input_dim = len(educ_data.columns)\n",
    "\n",
    "# Initialize parameters for learning rate \n",
    "learn_init = 0.1\n",
    "\n",
    "# Step 1: Initialize the weight vectors \n",
    "# Randomly generated matrix with entries between [-2,2], each column is a weight vector \n",
    "Weight_mat = 4*np.random.rand(input_dim,nodes_num)-2\n",
    "\n",
    "# Show initialized weight matrix\n",
    "print (\"Initialized weight matrix,\", Weight_mat)\n",
    "\n",
    "# Start SOM algorithm itterations\n",
    "for itter in range(total_itter):\n",
    "    \n",
    "    # Initialize distance from weight to chosen point (will be updated in inner loop)\n",
    "    dist_bmu = float(\"inf\")\n",
    "    \n",
    "    # Step 2: Choose data point at random from input data\n",
    "    \n",
    "    # Select row index at random\n",
    "    row_index = np.random.randint(len(educ_data.index))\n",
    "    \n",
    "    # Get corresponding data vector\n",
    "    data_chosen = educ_data.loc[[row_index]]\n",
    "    \n",
    "    # Step 3: Find the weight vector that is closest to chosen point\n",
    "    for node in range(nodes_num):\n",
    "        \n",
    "        # Compute euclidean distance from weight vector to chosen point\n",
    "        dist_neuron = np.linalg.norm(data_chosen-Weight_mat[:,node])\n",
    "        \n",
    "        # Save the node with shortest distance of its neuron to chose point\n",
    "        if dist_neuron < dist_bmu:\n",
    "            \n",
    "            # Update distance from weight to chosen point\n",
    "            dist_bmu = dist_neuron\n",
    "            \n",
    "            # Best matching unit (BMU)\n",
    "            weight_bmu = Weight_mat[:,node]\n",
    "            index_bmu = node\n",
    "            \n",
    "    # Step 4: Define radius of winning neuron neighbourhood \n",
    "    # We skip this step because we only have 3 neurons in our application\n",
    "    \n",
    "    # Define learning rate\n",
    "    learn_rate = learn_init*np.exp(-itter/total_itter)\n",
    "    \n",
    "    # Step 5: Update weight vectors (w_{t+1} = w_{t} + L(t)*(x_{i} - w_{t}))\n",
    "    Weight_mat[:,index_bmu] = np.add(weight_bmu,learn_rate*(np.subtract(data_chosen,weight_bmu)))\n",
    "\n",
    "# Show trained weights\n",
    "print (\"Trained weights from SOM,\", Weight_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vector the classifies each student into group 1,2,3\n",
    "group = np.zeros(len(educ_data.index))\n",
    "    \n",
    "# Classify input data\n",
    "for index, data in educ_data.iterrows():\n",
    "    \n",
    "    # Initialize distance from cluster centroid\n",
    "    dist_cluster = float(\"inf\")\n",
    "    \n",
    "    # Find closest weight centroid\n",
    "    for centroid in range(nodes_num):\n",
    "        \n",
    "        # Compute euclidean distance from centroid vector to data point\n",
    "        dist_centroid = np.linalg.norm(data-Weight_mat[:,centroid])\n",
    "\n",
    "        # Save centroid that is closest to data piont\n",
    "        if dist_centroid < dist_cluster:\n",
    "\n",
    "                # Update distance from weight to chosen point\n",
    "                dist_cluster = dist_centroid\n",
    "\n",
    "                # Best matching unit (BMU)\n",
    "                group[index] = centroid+1\n",
    "            \n",
    "# Add group classifier column \n",
    "educ_data[\"group\"] = group\n",
    "\n",
    "# See labeled data (last column contains labels)\n",
    "educ_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For group 1:\n",
    "# Notice the test scores are close to 0 standard deviations away from the mean\n",
    "# This is likely to be the \"average\" group\n",
    "educ_data[educ_data.group == 1].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}