{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595279501098",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_pre():\n",
    "\timport pickle\n",
    "\timport numpy as np\n",
    "\timport os.path\n",
    "\timport base64\n",
    "\tfrom PIL import Image\n",
    "\timport sys\n",
    "\n",
    "\tclass Preprocessor:\n",
    "\t\tdef __init__(self, fn=\"dataset.txt\"):\n",
    "\t\t\tself.datafile = fn\n",
    "\t\t\tself.target_shape = [20,20]\n",
    "\t\t\tself.splitchar = \"&\"\n",
    "\n",
    "\t\t\tif os.path.isfile(self.datafile):\n",
    "\t\t\t\twith open(fn, 'r') as f:\n",
    "\t\t\t\t\tself.vocab = eval(f.readline())\n",
    "\t\t\t\t\tassert type(self.vocab) is list, \"The first line of the file was not a vocab list.\"\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.vocab = None\n",
    "\n",
    "\t\tdef add_sample(self, data, index, vocab):\n",
    "\t\t\tassert self.vocab == vocab or self.vocab is None, \"Vocab list has changed. You cannot append to this dataset\"\n",
    "\t\t\tif self.vocab is None:\n",
    "\t\t\t\twith open(self.datafile, 'w') as f:\n",
    "\t\t\t\t\tv = str(vocab).replace(\"\\n\",\"\")\n",
    "\t\t\t\t\tf.write(v)\n",
    "\t\t\tself.vocab = vocab\n",
    "\t\t\tn = self.preprocess(data)\n",
    "\t\t\twith open(self.datafile, \"a\") as f:\n",
    "\t\t\t\tn = str(n.tolist()).replace(\"\\n\",\"\")\n",
    "\t\t\t\tf.write(\"\\n\" + str(self.vocab[index]) + self.splitchar + n)\n",
    "\n",
    "\t\tdef load_sample(self, line_i = 0):\n",
    "\t\t\tX = None ; y = None\n",
    "\t\t\tif os.path.isfile(self.datafile):\n",
    "\t\t\t\twith open(self.datafile, 'r') as f:\n",
    "\t\t\t\t\tvocab = eval(f.readline())\n",
    "\t\t\t\t\tassert vocab == self.vocab, \"The vocab for this datafile does not match the current vocab\"\n",
    "\n",
    "\t\t\t\twith open(self.datafile, \"r\") as f:\n",
    "\t\t\t\t\tlines = f.readlines()\n",
    "\t\t\t\t\tX = np.asarray(eval(lines[line_i + 1].split(self.splitchar)[1]))\n",
    "\t\t\t\t\ty = lines[line_i + 1].split(self.splitchar)[0]\n",
    "\t\t\t\treturn [X, y]\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\traise ValueError(\"Could not find the datafile\")\n",
    "\n",
    "\t\tdef load_all(self):\n",
    "\t\t\tX = None ; y = None\n",
    "\t\t\tif os.path.isfile(self.datafile):\n",
    "\t\t\t\twith open(self.datafile, 'r') as f:\n",
    "\t\t\t\t\tvocab = eval(f.readline())\n",
    "\t\t\t\t\tassert vocab == self.vocab, \"The vocab for this datafile does not match the current vocab\"\n",
    "\n",
    "\t\t\t\twith open(self.datafile, \"r\") as f:\n",
    "\t\t\t\t\tlines = f.readlines()\n",
    "\n",
    "\t\t\t\t\tX = np.zeros((len(lines) - 1, self.target_shape[0]*self.target_shape[1]))\n",
    "\t\t\t\t\ty = []\n",
    "\n",
    "\t\t\t\t\tfor i in range (len(lines)-1):\n",
    "\t\t\t\t\t\tX[i,:] = np.asarray(eval(lines[i + 1].split(self.splitchar)[1]))\n",
    "\t\t\t\t\t\ty.append(lines[i + 1].split(self.splitchar)[0])\n",
    "\t\t\t\t\ty = np.asarray(y)\n",
    "\t\t\t\treturn [X, y]\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\traise ValueError(\"Could not find the datafile\")\n",
    "\n",
    "\t\tdef preprocess(self, jpgtxt):\n",
    "\t\t\t# data = base64.decodestring(data)\n",
    "\t\t\tdata = jpgtxt.split(',')[-1]\n",
    "\t\t\tdata = base64.b64decode(data.encode('ascii'))\n",
    "\n",
    "\t\t\tg = open(\"temp.jpg\", \"wb\")\n",
    "\t\t\tg.write(data)\n",
    "\t\t\tg.close()\n",
    "\n",
    "\t\t\tpic = Image.open(\"temp.jpg\")\n",
    "\t\t\tM = np.array(pic) #now we have image data in numpy\n",
    "\n",
    "\t\t\tM = self.rgb2gray(M)\n",
    "\t\t\tM = self.squareTrim(M,threshold=0)\n",
    "\t\t\tM = self.naiveInterp2D(M,self.target_shape[0],self.target_shape[0])\n",
    "\t\t\t[N, mean, sigma] = self.normalize(M)\n",
    "\t\t\tn = N.reshape(-1)\n",
    "\t\t\tif np.isnan(np.sum(n)):\n",
    "\t\t\t\tn = np.zeros(n.shape)\n",
    "\t\t\treturn n\n",
    "\n",
    "\t\tdef dataset_length(self):\n",
    "\t\t\twith open(self.datafile) as f:\n",
    "\t\t\t\tfor i, l in enumerate(f):\n",
    "\t\t\t\t\tpass\n",
    "\t\t\treturn i + 1\n",
    "\n",
    "\t\t@staticmethod\n",
    "\t\tdef squareTrim(M, min_side=20, threshold=0):\n",
    "\t\t\tassert M.shape[0]==M.shape[1],\"Input matrix must be a square\"\n",
    "\t\t\twsum = np.sum(M,axis=0)\n",
    "\t\t\tnonzero = np.where(wsum > threshold*M.shape[1])[0]\n",
    "\t\t\tif len(nonzero) >=1:\n",
    "\t\t\t\twstart = nonzero[0]\n",
    "\t\t\t\twend = nonzero[-1]\n",
    "\t\t\telse:\n",
    "\t\t\t\twstart=0 ; wend = 0\n",
    "\n",
    "\t\t\thsum = np.sum(M,axis=1)\n",
    "\t\t\tnonzero = np.where(hsum > threshold*M.shape[0])[0]\n",
    "\t\t\tif len(nonzero) >=1:\n",
    "\t\t\t\thstart = nonzero[0]\n",
    "\t\t\t\thend = nonzero[-1]\n",
    "\t\t\telse:\n",
    "\t\t\t\thstart=0 ; hend = 0\n",
    "\n",
    "\t\t\tdiff = abs((wend-wstart) - (hend-hstart))\n",
    "\t\t\tif (wend-wstart > hend-hstart):\n",
    "\t\t\t\tside = max(wend-wstart+1, min_side)\n",
    "\t\t\t\tm = np.zeros((side, side))\n",
    "\t\t\t\tcropped = M[hstart:hend+1,wstart:wend+1]\n",
    "\t\t\t\tshift = diff/2\n",
    "\t\t\t\tm[shift:cropped.shape[0]+shift,:cropped.shape[1]] = cropped\n",
    "\t\t\telse:\n",
    "\t\t\t\tside = max(hend-hstart+1, min_side)\n",
    "\t\t\t\tm = np.zeros((side, side))\n",
    "\t\t\t\tcropped = M[hstart:hend+1,wstart:wend+1]\n",
    "\t\t\t\tshift=diff/2\n",
    "\t\t\t\tm[:cropped.shape[0],shift:cropped.shape[1]+shift] = cropped\n",
    "\t\t\treturn m\n",
    "\n",
    "\t\t@staticmethod\n",
    "\t\tdef rgb2gray(rgb):\n",
    "\t\t\tr, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "\t\t\tgray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\t\t\treturn gray\n",
    "\n",
    "\t\t@staticmethod\n",
    "\t\tdef naiveInterp2D(M, newx, newy):\n",
    "\t\t\tresult = np.zeros((newx,newy))\n",
    "\t\t\tfor i in range(M.shape[0]):\n",
    "\t\t\t\tfor j in range(M.shape[1]):\n",
    "\t\t\t\t\tindx = i*newx / M.shape[0]\n",
    "\t\t\t\t\tindy = j*newy / M.shape[1]\n",
    "\t\t\t\t\tresult[indx,indy] +=M[i,j]\n",
    "\t\t\treturn result\n",
    "\n",
    "\t\t@staticmethod\n",
    "\t\tdef normalize(M):\n",
    "\t\t\tsigma = np.std(M)\n",
    "\t\t\tmean = np.mean(M)\n",
    "\t\t\treturn [(M-mean)/sigma, mean, sigma]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle #saving and loading serialized model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#class for loading saved model and classifying new images \n",
    "class LiteOCR:\n",
    "\n",
    "    def __init__(self, fn='alpha-weights.pkl', pool_size=2):\n",
    "        #load the weights from the pickle file and the meta data\n",
    "        [weights, meta] = pickle.load(open(fn, 'rb'), encoding='latinl') #currently, this              #class MUST be initialized from a pickle file\n",
    "        #to store labels\n",
    "        self.vocab = meta['vocab']\n",
    "\n",
    "        #how many rows and columns in an image\n",
    "        self.img_rows = meta['img_side'] \n",
    "        self.img_cols = meta['img_side']\n",
    "\n",
    "        #load CNN\n",
    "        self.CNN = LiteCNN()\n",
    "        #with saved weights\n",
    "        self.CNN.load_weights(weights)\n",
    "        #define the pooling layers size\n",
    "        self.CNN.pool_size = int(pool_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, image):\n",
    "    print(image.shape)\n",
    "    #vectorize the image into the right shape for our network\n",
    "    X = np.reshape(image, (1, 1, self.img_rows, self.img_cols))\n",
    "    X = X.astype('float32')\n",
    "\n",
    "    #make the prediction\n",
    "    predicted_i = self.CNN.predict(X)   \n",
    "    #return the predicted label\n",
    "    return self.vocab[predicted_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 48)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m48\u001b[0m\n\u001b[1;33m    row_end = row_start + self.pool_size\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class LiteCNN:\n",
    "    def __init__(self):\n",
    "        # a place to store the layers\n",
    "        self.layers = [] \n",
    "        # size of pooling area for max pooling\n",
    "        self.pool_size = None \n",
    "\n",
    "    def load_weights(self, weights):\n",
    "        assert not self.layers, \"Weights can only be loaded once!\"\n",
    "        #add the saved matrix values to the convolutional network\n",
    "        for k in range(len(weights.keys())):\n",
    "            self.layers.append(weights['layer_{}'.format(k)])\n",
    "\n",
    "    def predict(self, X):        \n",
    "    #here is where the network magic happens at a high level\n",
    "        h = self.cnn_layer(X, layer_i=0, border_mode=\"full\"); X= h\n",
    "        h = self.relu_layer(X); X = h\n",
    "        h = self.cnn_layer(X, layer_i=2, border_mode=\"valid\"); X = h\n",
    "        h = self.relu_layer(X); X = h\n",
    "        h = self.maxpooling_layer(X); X = h\n",
    "        h = self.dropout_layer(X, .25); X = h\n",
    "        h = self.flatten_layer(X, layer_i=7); X = h\n",
    "        h = self.dense_layer(X, fully, layer_i=10); X = H\n",
    "        h = self.softmax_layer2D(X); X = h\n",
    "        max_i = self.classify(X)\n",
    "        return max_i[0]\n",
    "    \n",
    "    #given our feature map we've learned from convolving around the image\n",
    "    #lets make it more dense by performing pooling, specifically max pooling\n",
    "    #we'll select the max values from the image matrix and use that as our new feature map\n",
    "    def maxpooling_layer(self, convolved_features):\n",
    "        #given our learned features and images\n",
    "        nb_features = convolved_features.shape[0]\n",
    "        nb_images = convolved_features.shape[1]\n",
    "        conv_dim = convolved_features.shape[2]\n",
    "        res_dim = int(conv_dim / self.pool_size)       #assumed square shape\n",
    "\n",
    "        #initialize our more dense feature list as empty\n",
    "        pooled_features = np.zeros((nb_features, nb_images, res_dim, res_dim))\n",
    "        #for each image\n",
    "        for image_i in range(nb_images):\n",
    "            #and each feature map\n",
    "            for feature_i in range(nb_features):\n",
    "                #begin by the row\n",
    "                for pool_row in range(res_dim):\n",
    "                    #define start and end points\n",
    "\t                row_start = pool_row * self.pool_size\n",
    "                    row_end = row_start + self.pool_size\n",
    "\n",
    "                    #for each column (so its a 2D iteration)\n",
    "                    for pool_col in range(res_dim):\n",
    "                        #define start and end points\n",
    "\t                    col_start = pool_col * self.pool_size\n",
    "\t                    col_end   = col_start + self.pool_size\n",
    "                        \n",
    "                        #define a patch given our defined starting ending points\n",
    "                        patch = convolved_features[feature_i, image_i, row_start : row_end,col_start : col_end]\n",
    "                        #then take the max value from that patch\n",
    "                        #store it. this is our new learned feature/filter\n",
    "\t                    pooled_features[feature_i, image_i, pool_row, pool_col] = np.max(patch)\n",
    "        return pooled_features\n",
    "\n",
    "    #convolution is the most important of the matrix operations here\n",
    "    #well define our input, lauyer number, and a border mode (explained below)\n",
    "    def cnn_layer(self, X, layer_i=0, border_mode = \"full\"):\n",
    "        #we'll store our feature maps and bias value in these 2 vars\n",
    "        features = self.layers[layer_i][\"param_0\"]\n",
    "        bias = self.layers[layer_i][\"param_1\"]\n",
    "        #how big is our filter/patch?\n",
    "        patch_dim = features[0].shape[-1]\n",
    "        #how many features do we have?\n",
    "        nb_features = features.shape[0]\n",
    "        #How big is our image?\n",
    "        image_dim = X.shape[2] #assume image square\n",
    "        #R G B values\n",
    "        image_channels = X.shape[1]\n",
    "        #how many images do we have?\n",
    "        nb_images = X.shape[0]\n",
    "        \n",
    "        #With border mode \"full\" you get an output that is the \"full\" size as the input. \n",
    "        #That means that the filter has to go outside the bounds of the input by \"filter size / 2\" - \n",
    "        #the area outside of the input is normally padded with zeros.\n",
    "        if border_mode == \"full\":\n",
    "            conv_dim = image_dim + patch_dim - 1\n",
    "        #With border mode \"valid\" you get an output that is smaller than the input because \n",
    "        #the convolution is only computed where the input and the filter fully overlap.\n",
    "        elif border_mode == \"valid\":\n",
    "            conv_dim = image_dim - patch_dim + 1\n",
    "        \n",
    "        #we'll initialize our feature matrix\n",
    "        convolved_features = np.zeros((nb_images, nb_features, conv_dim, conv_dim));\n",
    "        #then we'll iterate through each image that we have\n",
    "        for image_i in range(nb_images):\n",
    "            #for each feature \n",
    "            for feature_i in range(nb_features):\n",
    "                #lets initialize a convolved image as empty\n",
    "                    convolved_image = np.zeros((conv_dim, conv_dim))\n",
    "                    #then for each channel (r g b )\n",
    "                for channel in range(image_channels):\n",
    "                    #lets extract a feature from our feature map\n",
    "                    feature = features[feature_i, channel, :, :]\n",
    "                    #then define a channel specific part of our image\n",
    "                    image   = X[image_i, channel, :, :]\n",
    "                    #perform convolution on our image, using a given feature filter\n",
    "                    convolved_image += self.convolve2d(image, feature, border_mode);\n",
    "\n",
    "                #add a bias to our convoved image\n",
    "                convolved_image = convolved_image + bias[feature_i]\n",
    "                #add it to our list of convolved features (learnings)\n",
    "                convolved_features[image_i, feature_i, :, :] = convolved_image\n",
    "        return convolved_features\n",
    "        #In a dense layer, every node in the layer is connected to every node in the preceding layer.\n",
    "    def dense_layer(self, X, layer_i=0):\n",
    "        #so we'll initialize our weight and bias for this layer\n",
    "        W = self.layers[layer_i][\"param_0\"]\n",
    "        b = self.layers[layer_i][\"param_1\"]\n",
    "        #and multiply it by our input (dot product)\n",
    "\t\toutput = np.dot(X, W) + b\n",
    "\t\treturn output\n",
    "\n",
    "    @staticmethod\n",
    "    \n",
    "#so what does the convolution operation look like?, given an image and a feature map (filter)\n",
    "    def convolve2d(image, feature, border_mode=\"full\"):\n",
    "        #we'll define the tensor dimensions of the image and the feature\n",
    "        image_dim = np.array(image.shape)\n",
    "        feature_dim = np.array(feature.shape)\n",
    "        #as well as a target dimension\n",
    "        target_dim = image_dim + feature_dim - 1\n",
    "        #then we'll perform a fast fourier transform on both the input and the filter\n",
    "        #performing a convolution can be written as a for loop but for many convolutions\n",
    "        #this approach is too comp. expensive/slow. it can be performed orders of magnitude\n",
    "        #faster using a fast fourier transform. \n",
    "        fft_result = np.fft.fft2(image, target_dim) * np.fft.fft2(feature, target_dim)\n",
    "        #and set the result to our target \n",
    "        target = np.fft.ifft2(fft_result).real\n",
    "\n",
    "        if border_mode == \"valid\":\n",
    "            # To compute a valid shape, either np.all(x_shape >= y_shape) or\n",
    "            # np.all(y_shape >= x_shape).\n",
    "            #decide a target dimension to convolve around\n",
    "            valid_dim = image_dim - feature_dim + 1\n",
    "            if np.any(valid_dim < 1):\n",
    "                valid_dim = feature_dim - image_dim + 1\n",
    "            start_i = (target_dim - valid_dim) // 2\n",
    "            end_i = start_i + valid_dim\n",
    "            target = target[start_i[0]:end_i[0], start_i[1]:end_i[1]]\n",
    "        return target\n",
    "\n",
    "    def relu_layer(x):\n",
    "        #turn all negative values in a matrix into zeros\n",
    "        z = np.zeros_like(x)\n",
    "        return np.where(x>z,x,z)\n",
    "\n",
    "    def softmax_layer2D(w):\n",
    "        #this function will calculate the probabilities of each\n",
    "        #target class over all possible target classes. \n",
    "        maxes = np.amax(w, axis=1)\n",
    "        maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "        e = np.exp(w - maxes)\n",
    "        dist = e / np.sum(e, axis=1, keepdims=True)\n",
    "        return dist\n",
    "\n",
    "    #affect the probability a node will be turned off by multiplying it\n",
    "    #by a p values (.25 we define)\n",
    "    def dropout_layer(X, p):\n",
    "        retain_prob = 1. - p\n",
    "        X *= retain_prob\n",
    "        return X\n",
    "\n",
    "    #get the largest probabililty value from the list\n",
    "    def classify(X):\n",
    "        return X.argmax(axis=-1)\n",
    "\n",
    "    #tensor transformation, less dimensions\n",
    "    def flatten_layer(X):\n",
    "        flatX = np.zeros((X.shape[0],np.prod(X.shape[1:])))\n",
    "        for i in range(X.shape[0]):\n",
    "            flatX[i,:] = X[i].flatten(order='C')\n",
    "        return flatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}